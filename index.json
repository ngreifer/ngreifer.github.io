[{"authors":null,"categories":null,"content":"I‚Äôm Noah Greifer (pronounced gree-fur; pronouns: he/him), a statistical consultant and programmer at Harvard University. I provide statistical consulting services as a member of the Data Science Services team at the Institute for Quantitative Social Science (IQSS) at Harvard. I also develop R packages, both as part of my job and in my personal time. Some of these packages include MatchIt, WeightIt, and cobalt, which facilitate the use of propensity score methods. See my other packages at the Software link above. I post on my blog about R programming, statistical analysis, and R package development.\nI currently reside in Cambridge, MA, but I grew up in Los Angeles, CA, and have lived in San Diego, CA, Portland, OR, and Durham, NC.\n Download my resum√©. -- ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"05d2cb0df913990c9440f73073d0c063","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I‚Äôm Noah Greifer (pronounced gree-fur; pronouns: he/him), a statistical consultant and programmer at Harvard University. I provide statistical consulting services as a member of the Data Science Services team at the Institute for Quantitative Social Science (IQSS) at Harvard.","tags":null,"title":"Noah Greifer","type":"authors"},{"authors":null,"categories":["R"],"content":" My R package WeightIt has a huge new update, making it one of the biggest updates since I started the project. Version 1.0.0 introduces a few breaking changes, including the possibility that old results will not align with results from newer version of the package. In most cases, though, this only means improvements (i.e., better balance).\nFor those that don‚Äôt know, WeightIt is an R package designed to provide access to propensity score weighting (also known as inverse probability weighting) and its variations in a way that facilitates the use of advanced and modern methods and best practices. It provides a simple, unified interface to many different methods of estimating weights to balance groups in observational studies, including those that use generalized linear models, machine learning methods, and convex optimization. WeightIt provides support for binary, multi-category, continuous, and longitudinal treatments and directly interfaces with cobalt for assessing balance after weighting.\nVersion 1.0.0 has several new features that I wanted to explain in a blog post rather than just in the NEWS document associated with the package because it‚Äôs important to me that these new features are appreciated. There are three primary updates that I‚Äôll discuss, along with some minor ones. Those three are updates to the covariate balancing propensity score, a new method called inverse probability tilting, and new support for fitting weighted outcome regression models that account for estimation of the weights in the standard errors.\nNew implementation of CBPS The covariate balancing propensity score (CBPS, Imai and Ratkovic 2014) is a method of estimating propensity scores using generalized linear models (e.g., logistic regression). I described CBPS in my last blog post, so I‚Äôll be brief here. Essentially, you have the score equations for a logistic regression, the roots of which are the logistic regression coefficients. You also have moment conditions that correspond to mean balance on the included covariates in the weighted sample. There are two versions of CBPS: the just-identified version, which finds the logistic regression coefficients that only solve the balance moment conditions, and the over-identified version, which finds the logistic regression coefficients that attempt to solve both the logistic regression score equations and the balance moments conditions. Because in general it is impossible to solve both sets of conditions exactly with a single set of coefficients, the conditions are weighted in a specific way to manage the trade-off between achieving balance and maximizing the likelihood using generalized method of moments (GMM) estimation. The form of this weighting occurs with a weighting matrix, which is a function of the coefficients and can either be estimated once, in what is called the ‚Äútwo-step‚Äù estimator, or it can be continuously updated as the coefficients are estimated.\nThere are versions of CBPS for the ATT, ATC, and ATE (logistic regression on its own is a CBPS for the ATO), as well as versions for multi-category and continuous treatments. The multi-category version replaces the logistic regression coefficients with coefficients in a multinomial logistic regression, and the continuous treatment version replaces the logistic regression coefficients with linear regression coefficients for the generalized propensity score (Fong, Hazlett, and Imai 2018). There is also a version for longitudinal treatments (Imai and Ratkovic 2015), but that has never been supported by WeightIt so I won‚Äôt discuss it here.\nPreviously, estimating the CBPS propensity scores and weights by specifying method = \u0026#34;cbps\u0026#34; in weightit() was done entirely in the CBPS package, which was written by the developers of the method. The package is great and does what it claims to do, but its code is very hard to read and debug, it is not very customizable, and there are ways in which the package is limited or buggy. I decided to finally figure out what CBPS was for myself as part of a broader task of understanding M-estimation (discussed later), and in doing so I realized I had the skills to program my own CBPS, and so that‚Äôs what I did, taking some inspiration from the original package. This means you can use CBPS in WeightIt without requiring CBPS as a dependency, and there are some additional options not available in CBPS that are now available to WeightIt users. I‚Äôll outline the main changes below:\n The default methods are now different, which is important when comparing the output of weightit() to that of CBPS::CBPS() or versions of WeightIt prior to 1.0.0. Now, the default is to use the just-identified version of CBPS, whereas previously the default was the over-identified version. The just-identified version has several benefits: 1) it is faster (since the over-identified version has to fit the just-identified version first anyway), 2) it yields better balance on the means, and 3) it is compatible with using M-estimation to ‚Ä¶","date":1710979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710979200,"objectID":"d8a1fba90a4e3ca5782f71a10a635577","permalink":"https://ngreifer.github.io/blog/what-s-new-in-weightit-version-1-0-0/","publishdate":"2024-03-21T00:00:00Z","relpermalink":"/blog/what-s-new-in-weightit-version-1-0-0/","section":"blog","summary":"My R package WeightIt has a huge new update, making it one of the biggest updates since I started the project. Version 1.0.0 introduces a few breaking changes, including the possibility that old results will not align with results from newer version of the package.","tags":["R","propensity-scores"],"title":"What's New in `WeightIt` Version 1.0.0","type":"blog"},{"authors":[],"categories":[],"content":" As I‚Äôve been studying M-estimation and the covariate balancing propensity score (CBPS) (Imai and Ratkovic 2014), I‚Äôve been noticing some interesting connections between these methods and want to share them with you.\nLogistic Regression and M-estimation First, what is logistic regression? I‚Äôll discuss that in more detail in another post, but briefly it‚Äôs a way of modeling the relationship between \\(K\\) predictors \\(\\mathbf{X}\\) (which include an intercept) and an outcome \\(A\\) (yes, I‚Äôll use \\(A\\) for the outcome, and I‚Äôll also use it to mean the treatment in an observational study since the context is fitting a model for the treatment to estimate propensity scores), where that relationship is specified to be\n\\[ p_i = P(A_i = 1|\\mathbf{X}_i)=\\text{expit}(\\mathbf{X}_i\\beta) \\]\nwhere \\(\\text{expit}(z)=1/(1 + e^{-z})\\). Expit is also known as inverse logit, i.e., as \\(\\text{logit}^{-1}(z)\\) where \\(\\text{logit}(p)=\\ln\\frac{p}{1-p}\\). We estimate \\(\\beta\\) usually using maximum likelihood, but here I‚Äôm going to talk about M-estimation (Stefanski and Boos 2002; Ross et al. 2024), in which we specify a ‚Äústack‚Äù of estimating equations and find the values of \\(\\beta\\) such that all the estimating equations are equal to 0. That is, we specify the \\(K\\) estimating equations\n\\[ \\frac{1}{N}\\sum_{i=1}^N{\\left(\\array{s_1(\\beta, A_i,\\mathbf{X}_i) \\\\ \\dots \\\\ s_K(\\beta, A_i,\\mathbf{X}_i)}\\right)}=\\mathbf{0} \\]\nand find the values of \\(\\beta\\) that satisfy the equation. This is called finding the ‚Äúroots‚Äù of the estimating equations. There is an estimating equation for each parameter to be estimated. When the estimating equations are the partial derivatives of the log likelihood with respect to each coefficient, then then \\(\\beta\\) that solve the estimating equations are also the maximum likelihood estimates1.\nFor logistic regression, the \\(K\\) estimating estimating equations (one for each coefficient indexed by \\(k\\)) look like the following:\n\\[ \\frac{1}{N}\\sum_{i=1}^N{(A_i-p_i)X_{ki}}=0 \\]\nIt‚Äôs kind of crazy that it‚Äôs so simple when logistic regression seems so complicated and nonlinear. We estimate the coefficients in logistic regression simply by finding the values of \\(\\beta\\) that are used to compute \\(p_i\\) that make this estimating equation equal 0 for each predictor. In practice, this can be done by using a ‚Äúroot-solver‚Äù, i.e., a function that finds the roots of a system of equations.\nAnother cool thing (which we‚Äôll come back to) is that this estimating equation is not just for logistic regression but is also for any generalized linear model with a canonical link; indeed, that‚Äôs what defines the canonical link. For binomial regression, the logit link is the canonical link. For Poisson regression, it‚Äôs the log link, and for linear regression, it‚Äôs the identity link. That is, these three models can be estimated using the exact estimating equations I wrote above but with \\(p_i\\) computed using the respective formula (\\(p_i=\\exp(\\mathbf{X}_i\\beta)\\) for the log link and \\(p_i=\\mathbf{X}_i\\beta\\) for the identity link).\n Covariate Balancing Propensity Score (CBPS) You may have heard of CBPS before; it‚Äôs a way of estimating the propensity score in an observational study using logistic regression in such a way that balance is automatically achieved on the covariate means. How does this work? Instead of using the above estimation equations to estimate the coefficients, CBPS uses a different set of estimation equations, in particular2\n\\[ \\frac{1}{N}\\sum_{i=1}^N{\\left(\\frac{A_i}{p_i} - \\frac{1-A_i}{1-p_i}\\right)X_{ki}}=0 \\]\nThe keen propensity score weighting enjoyer might notice something familiar about this estimating equation; it looks a lot like the weighted mean difference of \\(X_k\\) when using inverse probability weights for the ATE, that is \\(w^{ATE}_i=\\frac{A_i}{p_i} + \\frac{1-A_i}{1-p_i}\\). And indeed, this is so! The weighted difference in means is usually expressed as \\(\\frac{\\sum_i{w_i A_i X_{ki}}}{\\sum{w_i A_i}} - \\frac{\\sum_i{w_i (1-A_i) X_{ki}}}{\\sum{w_i (1-A_i)}}\\), but when \\(\\sum_i{A_i/p_i} = \\sum_i{(1-A_i)/(1-p_i)}\\), which is satisfied when an intercept is in \\(\\mathbf{X}\\), the estimating equation and the weighted difference in means are identical. That means what CBPS does is find the coefficients \\(\\beta\\) such that weighted difference in means is equal to 0 for each covariate \\(X_k\\) when the weights are computed using the ATE formula applied to the probabilities generated by \\(\\beta\\). It‚Äôs pretty ingenious, which is why it made such a splash!\nThe idea of using estimating equations that correspond to covariate balance was also proposed by Graham, De Xavier Pinto, and Egel (2012) as ‚Äúinverse probability tilting‚Äù; it turns out when applied to the ATT (described later) these methods are identical.\n ATO Weights A propensity score weighting enjoyer may have also heard of overlap weights or ATO weights (Li, Morgan, and Zaslavsky 2018). These are weights computed as \\[ w^{ATO}_i=A_i(1-p_i) + ‚Ä¶","date":1710201600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710201600,"objectID":"a7864aa3400b1d67be901a4aa82906d8","permalink":"https://ngreifer.github.io/blog/logistic-regression-cbps-overlap-weights/","publishdate":"2024-03-12T00:00:00Z","relpermalink":"/blog/logistic-regression-cbps-overlap-weights/","section":"blog","summary":"As I‚Äôve been studying M-estimation and the covariate balancing propensity score (CBPS) (Imai and Ratkovic 2014), I‚Äôve been noticing some interesting connections between these methods and want to share them with you.","tags":["logistic regression","propensity-scores"],"title":"Musings on Logistic Regression, CBPS, and Overlap Weights","type":"blog"},{"authors":null,"categories":null,"content":" I‚Äôm often asked how the matching weights produced by MatchIt are computed. The weights are necessary for estimating the treatment effect in the matched sample; indeed, the weights determine the matched sample. While the weights for simple methods like 1:1 matching are straightforward (i.e., 1 if matched and 0 if unmatched), for more complicated scenarios, like full matching, matching with replacement, and variable ratio matching, the weights take on variable values and are critical to include in the analysis of the matched dataset. For example, full matching doesn‚Äôt discard any units (by default), but failing to include the matching weights in the estimation of the treatment effect would be like doing no matching at all.\nThere is very little guidance in the literature on how to compute matching weights. We have a few clues that have been scattered across different fields, but they have yet to describe a unifying method of computing these weights1. In this post, I‚Äôll describe how matching weights are computed in MatchIt and how this unifying method relates to the few strategies described in the literature.\nThe main theses of this post are that matching is a nonparametric method for estimating propensity scores, and matching weights are propensity score weights. This framework unifies existing approaches for computing weights after matching, applies to all forms of matching (including \\(k\\):1 matching, full matching, and stratification), and is straightforward to implement.\nMatching as Nonparametric Estimation of Propensity Scores The first step in understanding how matching weights are computed is to consider how matching is a nonparametric estimator of the propensity score. When I talk about matching here, I‚Äôm really talking about the assignment of units into pairs, strata, or matched sets (Greifer and Stuart 2021). For example, 1:1 pair matching assigns treated and control units into pairs, each with one treated and one control unit. Optimal full matching assigns all units into matched sets, each with either exactly one treated unit and one or more control units or with exactly one control units and one or more treated units (Hansen and Klopfer 2006). Propensity score subclassification and coarsened exact matching assign units into strata based on their values of the propensity score or covariates, respectively (Rosenbaum and Rubin 1984; Iacus, King, and Porro 2012). I do want to note that matching with replacement is a slightly different beast, so I will save my discussion of it till later, though how it fits into this framework is straightforward.\nComputing stratum propensity scores For matched units, we can compute a new ‚Äústratum‚Äù propensity score, \\(\\hat{e}^*_i\\) as \\[ \\hat{e}^*_i = P(A = 1|S=s_i) \\]where \\(A\\) is the treatment (0 for control, 1 for treated) and \\(S\\) is stratum/pair membership indexed by strata \\(s\\). Put in words, the stratum propensity score \\(\\hat{e}^*_i\\) for each member of a matched stratum is the proportion of treated units in that stratum. We can also write this formula as \\[ \\hat{e}^*_i = \\frac{n_{1s_i}}{n_{s_i}} \\] where \\(n_{1s_i}\\) is the number of treated units in stratum \\(s_i\\) and \\(n_{s_i}\\) is the total number of units in stratum \\(s_i\\).\nNote that \\(\\hat{e}^*_i\\) is distinct from the usual propensity score, \\(\\hat{e}_i = P(A=1|X = x_i)\\), which is estimated from the treatment and covariates using, e.g., logistic regression or a machine learning model. \\(\\hat{e}_i\\) may be used to perform the matching or subclassification, but it is \\(\\hat{e}^*_i\\), the subject of this post, that arises from matching or subclassification. It is critical to keep these two propensity scores distinct; one is used to match (\\(\\hat{e}_i\\)), and the other results from matching (\\(\\hat{e}^*_i\\)).\nThis method of estimating stratum propensity scores is nonparametric in the sense that no model is used and no functional form assumption are made, once units have been assigned into strata. It may be that a model was used to assign units into strata (e.g., when matching or subclassifying based on a propensity score estimated with a model of treatment given the covariates), but, given the matching, this new propensity score is nonparametric. It is agnostic to how the matching was done.\nIntuitively, we can think of stratum membership as a proxy for the covariates that are usually included in a propensity score specification. That is, if all units in a stratum have the same values of the covariates, conditioning on stratum membership is the same as conditioning on the covariates.\n Examples In full matching, we may have some matched sets that have, for example, 1 treated unit and 7 control units. All units in that stratum would receive a stratum propensity score of \\(1/8\\). We might have another matched set that has 5 treated units and 1 control unit. All units in that stratum would receive a stratum propensity score of \\(5/6\\).\nIn 1:1 matching, the situation is more trivial; all matched units, which ‚Ä¶","date":1685404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685404800,"objectID":"b8a60f781641f48a3be9f5147a2771c0","permalink":"https://ngreifer.github.io/blog/matching-weights/","publishdate":"2023-05-30T00:00:00Z","relpermalink":"/blog/matching-weights/","section":"blog","summary":"I‚Äôm often asked how the matching weights produced by MatchIt are computed. The weights are necessary for estimating the treatment effect in the matched sample; indeed, the weights determine the matched sample.","tags":["matching","propensity-scores"],"title":"Matching Weights are Propensity Score Weights","type":"blog"},{"authors":null,"categories":["R"],"content":" Multiply imputed data always makes things a little harder. Essentially, you have to perform each step of the analysis in each imputed dataset and then combine the results together in a special way. For basic regression analysis, the mice package makes fitting models and combining estimates simple. But when we want to do propensity score matching or weighting before fitting our regression models, and when the quantity we want to estimate is not just a coefficient in a regression model, things get a bit harder.\nFor doing matching or weighting in multiply imputed data, the R package {MatchThem} does the job. It essentially provides wrappers for MatchIt::matchit() and WeightIt::weightit() for multiply imputed data. It extends {mice}‚Äôs functionality for fitting regression models in multiply imputed data by automatically incorporating the matched or weighted structure into the estimation of the outcome models. It uses mice::pool() to pool estimates across multiply imputed data.\nBut for estimating treatment effects, it‚Äôs often not as simple as using a regression coefficient. If we include covariates in our outcome model but want a marginal effect, we need to use an average marginal effects procedure (i.e., g-computation) to compute it within each imputed dataset, and then combine the results afterward. The {marginaleffects} package provides a wonderful interface for performing g-computation, but for multiply imputed data, it can require some programming by the analyst. In this guide, I‚Äôll show you how to do that programming to combine treatment effect estimates across multiple imputed datasets.\nAn alternative to using {marginaleffects} is to use the {clarify} package. {clarify} can also be used to perform g-computation, but it uses simulation-based inference to compute the uncertainty bounds for the estimate. An advantage of simulation-based inference for multiply imputed data is that combining estimates across imputed datasets is much more straightforward. In this guide, I‚Äôll also show you how to use {clarify} to combine treatment effect estimates across imputed datasets.\nPackages we‚Äôll need We will need the following packages for this demonstration: cobalt, mice, MatchThem, WeightIt, marginaleffects, and clarify.\n The data As usual, we‚Äôll be using a version of the lalonde dataset. Here will use the lalonde_mis dataset in {cobalt}, which has missing values.\ndata(\u0026#34;lalonde_mis\u0026#34;, package = \u0026#34;cobalt\u0026#34;) summary(lalonde_mis) ## treat age educ race married nodegree re74 re75 re78 ## Min. :0.0000 Min. :16.00 Min. : 0.00 black :243 Min. :0.0000 Min. :0.0000 Min. : 0.0 Min. : 0.0 Min. : 0.0 ## 1st Qu.:0.0000 1st Qu.:20.00 1st Qu.: 9.00 hispan: 72 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.: 0.0 1st Qu.: 0.0 1st Qu.: 238.3 ## Median :0.0000 Median :25.00 Median :11.00 white :299 Median :0.0000 Median :1.0000 Median : 984.5 Median : 585.4 Median : 4759.0 ## Mean :0.3013 Mean :27.36 Mean :10.27 Mean :0.4158 Mean :0.6303 Mean : 4420.2 Mean : 2170.3 Mean : 6792.8 ## 3rd Qu.:1.0000 3rd Qu.:32.00 3rd Qu.:12.00 3rd Qu.:1.0000 3rd Qu.:1.0000 3rd Qu.: 7626.9 3rd Qu.: 3202.0 3rd Qu.:10893.6 ## Max. :1.0000 Max. :55.00 Max. :18.00 Max. :1.0000 Max. :1.0000 Max. :35040.1 Max. :25142.2 Max. :60307.9 ## NA\u0026#39;s :20 NA\u0026#39;s :40 NA\u0026#39;s :39 You can see there are some missing values in married, re74, and re75.\n Imputing the data Here, we‚Äôll use {mice} to impute the data. Although typically something like 20 imputation is sufficient, for the method {clarify} uses, it needs way more, so we‚Äôll use 50. We‚Äôll use the default settings, but you should tailor the imputation to fit the needs of your dataset. (I always like to use a machine learning method for my imputations). We‚Äôll also set a seed to ensure replicability.\nlibrary(\u0026#34;mice\u0026#34;) set.seed(12345) imp \u0026lt;- mice(lalonde_mis, m = 50, printFlag = FALSE) mice() returns a mids object, which contains the imputed datasets. Although we could extract the datasets using complete(), we‚Äôll supply this object directly to our function for estimating the propensity score weights.\n Weighting the imputed data We‚Äôll use MatchThem::weightthem() to estimate propensity score weights in the imputed datasets. We could also use MatchThem::matchthem() to do matching; the process is basically identical1. Here we‚Äôll use logistic regression (ü§¢) to estimate ATT weights to keep things quick and simple.\nlibrary(\u0026#34;MatchThem\u0026#34;) w.imp \u0026lt;- weightthem(treat ~ age + educ + race + married + nodegree + re74 + re75, data = imp, method = \u0026#34;ps\u0026#34;, estimand = \u0026#34;ATT\u0026#34;) Let‚Äôs assess balance using {cobalt}.\nlibrary(\u0026#34;cobalt\u0026#34;) bal.tab(w.imp, stats = c(\u0026#34;m\u0026#34;, \u0026#34;ks\u0026#34;), abs = TRUE) ## Balance summary across all imputations ## Type Mean.Diff.Adj Max.Diff.Adj Mean.KS.Adj Max.KS.Adj ## prop.score Distance 0.0235 0.0379 0.1166 0.1327 ## age Contin. 0.1120 0.1343 0.3053 0.3146 ## educ Contin. 0.0352 0.0485 0.0369 0.0412 ## race_black Binary 0.0024 0.0036 0.0024 0.0036 ## race_hispan Binary 0.0003 0.0007 0.0003 0.0007 ## race_white Binary 0.0022 0.0030 0.0022 0.0030 ## married ‚Ä¶","date":1675987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675987200,"objectID":"234eb4b23fdb18962d30bce146912cbd","permalink":"https://ngreifer.github.io/blog/treatment-effects-mi/","publishdate":"2023-02-10T00:00:00Z","relpermalink":"/blog/treatment-effects-mi/","section":"blog","summary":"Multiply imputed data always makes things a little harder. Essentially, you have to perform each step of the analysis in each imputed dataset and then combine the results together in a special way.","tags":["propensity-scores","R","multiple-imputation"],"title":"Estimating Treatment Effects After Weighting with Multiply Imputed Data","type":"blog"},{"authors":null,"categories":null,"content":" Genetic matching sounds cool and science-y, something we social scientists love because nobody thinks what we do is ‚Äúreal‚Äù science. And genetic matching is cool and science-y, but not because it has anything to do with genes or DNA. Genetic matching is a method of adjusting for confounding in observational studies; it is a close relative of propensity score matching and Mahalanobis distance matching and serves exactly the same purpose. Sekhon (2011) and Diamond and Sekhon (2013) describe genetic matching, but I‚Äôll explain it here in simple terms and with an emphasis on its generality, which is undersold by its implementations.\nThis post won‚Äôt make any sense if you don‚Äôt know what matching in general is. Go read Stuart (2010), Greifer and Stuart (2021), and the MatchIt vignette on matching methods to learn about them. The focus here will be on pair matching, which involves assigning units to pairs or strata based on the distances between them, then discarding unpaired units.\nThe goal of matching is balanced samples, i.e., samples where the distribution of covariates in the treated and control groups is the same so that an estimated treatment effect cannot be said to be due to differences in the covariate distributions. Why, then, do we make pairs? Close pairs create balance, in theory. How do we compute how close units are to each other? There are several ways; a common one is the Mahalanobis distance, as described for matching in Rubin (1980), and which I‚Äôll describe here.\nThe Mahalanobis distance between two units \\(i\\) and \\(j\\) is defined as\n\\[ \\delta^{md}_{i,j}=\\sqrt{(\\mathbf{x}_i-\\mathbf{x}_j)\\Sigma^{-1}(\\mathbf{x}_i-\\mathbf{x}_j)\u0026#39;} \\]\nwhere \\(\\mathbf{x}_i\\) is the vector of covariates for unit \\(i\\) (i.e., that unit‚Äôs row in the dataset) and \\(\\Sigma\\) is the covariance matrix of the covariates1. Equivalently, the Mahalanobis distance is the Euclidean distance (i.e., the regular distance) computed on the standardized principal components. The Mahalanobis distance is an improvement over the Euclidean distance of the covariates because it standardizes the covariates to be on the same scale and adjusts for correlations between covariates (so two highly correlated variables only count once). A great description of the Mahalanobis distance is here (though there it is not described in the context of matching).\nGenetic matching concerns a generalization of the Mahalanobis distance, called the generalized Mahalanobis distance, which additionally involves a weight matrix. The generalized Mahalanobis distance is defined as\n\\[ \\delta^{gmd}_{i,j}(W)=\\sqrt{(\\mathbf{x}_i-\\mathbf{x}_j)\u0026#39;\\left(\\Sigma^{-\\frac{1}{2}}\\right)\u0026#39; W\\Sigma^{-\\frac{1}{2}}(\\mathbf{x}_i-\\mathbf{x}_j)} \\]\nwhere \\(\\Sigma^{-\\frac{1}{2}}\\) is the ‚Äúsquare root‚Äù of the inverse of the covariance matrix (e.g., the Cholesky decomposition), and \\(W\\) is a symmetric weight matrix that can contain anything but in most cases is a diagonal matrix with a scalar weight for each covariate in \\(\\mathbf{x}\\) (not weights for each unit like in propensity score weighting; a weight for each covariate), i.e., \\(W = \\text{diag}(\\begin{bmatrix} w_1 \u0026amp; \\dots \u0026amp; w_p \\end{bmatrix})\\). The generalized Mahalanobis distance is equal to the usual Mahalanobis distance when \\(W=I\\), the identity matrix.\nWhat does any of this have to do with genetic matching? Well, ‚Äúgenetic matching‚Äù is a bit of a misnomer; it‚Äôs not a matching method. It‚Äôs a method of estimating \\(W\\). Genetic matching finds the \\(W\\) that, when incorporated in a generalized Mahalanobis distance used to match treated and control units, yields the best balance. Once you have found \\(W\\), you then do a regular round of matching, and that is your matched sample.\nTo put it slightly more formally, consider a function \\(\\text{match}(\\delta)\\), which takes in a distance matrix \\(\\delta\\) and produces a matched set of treated and control units, characterized by a set of matching weights (e.g., 1 if matched, 0 if unmatched) and pair membership for each unit. Consider a function \\(\\text{imbalance}(m)\\), which takes in the output of a \\(\\text{match}(\\delta)\\) and returns a scalar imbalance metric (e.g., the largest absolute standardized mean difference among all the covariates). We can then write the genetic matching problem as the following:\n\\[ \\underset{W}{\\operatorname{arg\\,min}} \\, \\text{imbalance}(\\text{match}(\\delta^{gmd}(W))) \\]\nGenetic matching is very general; there are many ways to do the matching (i.e., many ways to specify the \\(\\text{match}()\\) function) and many ways to characterize imbalance (i.e., many ways to specify the \\(\\text{imbalance}()\\) function) (and even several ways to specific \\(\\delta()\\)!). Although nearest neighbor matching is often used for \\(\\text{match}()\\), any matching method that uses a distance matrix could be as well. A specific imbalance measure (which I‚Äôll explain in more detail later) is most often used for \\(\\text{imbalance}()\\) because it is the default in the software that ‚Ä¶","date":1665187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665187200,"objectID":"1b788514d90afeaa9df4e6c04f68115a","permalink":"https://ngreifer.github.io/blog/genetic-matching/","publishdate":"2022-10-08T00:00:00Z","relpermalink":"/blog/genetic-matching/","section":"blog","summary":"Genetic matching sounds cool and science-y, something we social scientists love because nobody thinks what we do is ‚Äúreal‚Äù science. And genetic matching is cool and science-y, but not because it has anything to do with genes or DNA.","tags":["matching","R"],"title":"Genetic Matching, from the Ground Up","type":"blog"},{"authors":null,"categories":null,"content":" Today I‚Äôm going to demonstrate performing a subgroup analysis after propensity score matching using R. Subgroup analysis, also known as moderation analysis or the analysis of effect modification, concerns the estimation of treatment effects within subgroups of a pre-treatment covariate. This post assumes you understand how to do propensity score matching. For a general introduction to propensity score matching, I recommend Austin (2011) and the {MatchIt} introductory vignette. If you understand inverse probability weighting but aren‚Äôt too familiar with matching, I recommend my article with Liz Stuart (Greifer and Stuart 2021). For an introduction to subgroup analysis with propensity scores, you can also check out Green and Stuart (2014). Here, I‚Äôll mainly try to get to the point.\nThe dataset we‚Äôll use today is the famous Lalonde dataset, investigating the effect of a job training program on earnings. We‚Äôll use the version of this dataset that comes with the {MatchIt} package.\ndata(\u0026#34;lalonde\u0026#34;, package = \u0026#34;MatchIt\u0026#34;) head(lalonde) ## treat age educ race married nodegree re74 re75 re78 ## NSW1 1 37 11 black 1 1 0 0 9930.0460 ## NSW2 1 22 9 hispan 0 1 0 0 3595.8940 ## NSW3 1 30 12 black 0 0 0 0 24909.4500 ## NSW4 1 27 11 black 0 1 0 0 7506.1460 ## NSW5 1 33 8 black 0 1 0 0 289.7899 ## NSW6 1 22 9 black 0 1 0 0 4056.4940 The treatment is treat, the outcome in the original study was re78 (1978 earnings), and the other variables are pretreatment covariates that we want to adjust for using propensity score matching. In this example, I‚Äôll actually be using a different outcome, re78_0, which is whether the participant‚Äôs 1978 earnings were equal to 0 or not, because I want to demonstrate the procedure for a binary outcome. So, we hope the treatment effect is negative, i.e., the risk of 0 earnings decreases for those in the treatment.\nlalonde$re78_0 \u0026lt;- as.numeric(lalonde$re78 == 0) Our moderator will be race, a 3-category factor variable.\nwith(lalonde, table(race)) ## race ## black hispan white ## 243 72 299 Our estimand will be the subgroup-specific and marginal average treatment effect on the treated (ATT), using the risk difference as our effect measure.\nPackages You‚Äôll Need We‚Äôll need a few R packages for this analysis. We‚Äôll need {MatchIt} and {optmatch} for the matching, {cobalt} for the balance assessment, {marginaleffects} for estimating the treatment effects, and {sandwich} for computing the standard errors. You can install those using the code below:\ninstall.packages(c(\u0026#34;MatchIt\u0026#34;, \u0026#34;optmatch\u0026#34;, \u0026#34;cobalt\u0026#34;, \u0026#34;marginaleffects\u0026#34;, \u0026#34;sandwich\u0026#34;)) Let‚Äôs get into it!\n Step 1: Subgroup Matching Our first step is to perform the matching. Although there are a few strategies for performing matching for subgroup analysis, in general subgroup-specific matching tends to work best, though it requires a little extra work.\nWe‚Äôll do this by splitting the dataset by race and performing a separate matching analysis within each one.\n#Splitting the data lalonde_b \u0026lt;- subset(lalonde, race == \u0026#34;black\u0026#34;) lalonde_h \u0026lt;- subset(lalonde, race == \u0026#34;hispan\u0026#34;) lalonde_w \u0026lt;- subset(lalonde, race == \u0026#34;white\u0026#34;) Here we‚Äôll use full matching because 1:1 matching without replacement, the most common (but worst) way to do propensity score matching, doesn‚Äôt work well in this dataset. The process described below works exactly the same for 1:1 and most other kinds of matching as it does for full matching. We‚Äôll estimate propensity scores in each subgroup, here using probit regression, which happens to yield better balance than logistic regression does.\nlibrary(\u0026#34;MatchIt\u0026#34;) #Matching in race == \u0026#34;black\u0026#34; m.out_b \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_b, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;) #Matching in race == \u0026#34;hispan\u0026#34; m.out_h \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_h, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;) #Matching in race == \u0026#34;black\u0026#34; m.out_w \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_w, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;)  Step 2: Assessing Balance within Subgroups We need to assess subgroup balance; we can do that using summary() on each matchit object, or we can use functions from {cobalt}.\nBelow are examples of using summary() and cobalt::bal.tab() on one matchit object at a time1:\nsummary(m.out_b) ## ## Call: ## matchit(formula = treat ~ age + educ + married + nodegree + re74 + ## re75, data = lalonde_b, method = \u0026#34;full\u0026#34;, link = \u0026#34;probit\u0026#34;, ## estimand = \u0026#34;ATT\u0026#34;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6587 0.6121 0.4851 0.7278 0.1134 0.1972 ## age 25.9808 26.0690 -0.0121 0.4511 0.0902 0.2378 ## educ 10.3141 10.0920 0.1079 0.5436 0.0336 0.0807 ## married 0.1859 0.2874 -0.2608 . 0.1015 0.1015 ## nodegree 0.7244 0.6437 0.1806 . 0.0807 0.0807 ## re74 2155.0132 3117.0584 -0.1881 0.9436 0.0890 0.2863 ## re75 1490.7221 1834.4220 ‚Ä¶","date":1662336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662336000,"objectID":"2ce2bc3725b3a8aff6cde5b4b0c90240","permalink":"https://ngreifer.github.io/blog/subgroup-analysis-psm/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/blog/subgroup-analysis-psm/","section":"blog","summary":"Today I‚Äôm going to demonstrate performing a subgroup analysis after propensity score matching using R. Subgroup analysis, also known as moderation analysis or the analysis of effect modification, concerns the estimation of treatment effects within subgroups of a pre-treatment covariate.","tags":["matching","propensity-scores","R","subgroup analysis"],"title":"Subgroup Analysis After Propensity Score Matching Using R","type":"blog"},{"authors":null,"categories":null,"content":"This page documents the software packages I have worked on. If you have any questions about them, please submit your question to their GitHub issues page rather than emailing me. You are also welcome to ask a question on StackOverflow or CrossValidated, which I check often.\nR packages These packages are ones that I am a primary author on and have expertise on the methods implemented. I consider these packages to be ‚Äúmine‚Äù, at least partly, in the sense that I can speak not only on the implementation but on the methods as well.\n cobalt: Covariate Balance Tables and Plots  Noah Greifer | website | CRAN | source   WeightIt: Weighting for Covariate Balance in Observational Studies  Noah Greifer | website | CRAN | source   MatchIt: Nonparametric Preprocessing for Parametric Causal Inference  Daniel Ho, Kosuke Imai, Gary King, Elizabeth Stuart, and Noah Greifer | website | CRAN | source   MatchThem: Matching and Weighting Multiply Imputed Datasets  Farhad Pishgar and Noah Greifer | CRAN | source   optweight: Targeted Stable Balancing Weights Using Optimization  Noah Greifer | CRAN | source   MatchingFrontier: Computation of the Balance-Sample Size Frontier in Matching Methods for Causal Inference  Gary King, Christopher Lucas, Richard Nielsen, and Noah Greifer | website | source   fwb: Fractional Weighted Bootstrap  Noah Greifer | website | CRAN | source   clarify: Simulation-Based Inference for Regression Models  Noah Greifer, Steven Worthington, Stefano Iacus, and Gary King | website | CRAN | source   lmw: Linear Model Weights  Ambarish Chattopadhyay, Noah Greifer, and Jos√© Zubizarreta | CRAN | source    These packages are ones that I have developed as part of my job but which I don‚Äôt consider ‚Äúmine‚Äù in the sense that I am not the primary maintainer and I don‚Äôt have expertise on the methods implemented. Please do not contact me about these packages.\n  netlit: Augment a literature review with network analysis statistics\n Devin Judge-Lord and Noah Greifer | website | source    EvoPhylo: Pre- And Postprocessing of Morphological Data from Relaxed Clock Bayesian Phylogenetics\n Tiago Sim√µes, Noah Greifer, and Stephanie Pierce | website | CRAN | source    Morphoscape: Computation and Visualization of Adaptive Landscapes\n Blake Dickson, Stephanie Pierce, and Noah Greifer | website | CRAN | source    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6fcae98d7df3b6c44952e7b5fed181e3","permalink":"https://ngreifer.github.io/software/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/software/","section":"","summary":"This page documents the software packages I have worked on. If you have any questions about them, please submit your question to their GitHub issues page rather than emailing me. You are also welcome to ask a question on StackOverflow or CrossValidated, which I check often.","tags":null,"title":"Software","type":"page"}]