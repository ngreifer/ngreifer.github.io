[{"authors":null,"categories":null,"content":"I’m Noah Greifer (pronounced gree-fur; pronouns: he/him), a statistical consultant and programmer at Harvard University. I provide statistical consulting services as a member of the Data Science Services team at the Institute for Quantitative Social Science (IQSS) at Harvard. I also develop R packages, both as part of my job and in my personal time. Some of these packages include MatchIt, WeightIt, and cobalt, which facilitate the use of propensity score methods. See my other packages at the Software link above. I post on my blog about R programming, statistical analysis, and R package development.\nI currently reside in Cambridge, MA, but I grew up in Los Angeles, CA, and have lived in San Diego, CA, Portland, OR, and Durham, NC.\n Download my resumé. -- ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"05d2cb0df913990c9440f73073d0c063","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m Noah Greifer (pronounced gree-fur; pronouns: he/him), a statistical consultant and programmer at Harvard University. I provide statistical consulting services as a member of the Data Science Services team at the Institute for Quantitative Social Science (IQSS) at Harvard.","tags":null,"title":"Noah Greifer","type":"authors"},{"authors":null,"categories":null,"content":" I’m often asked how the matching weights produced by MatchIt are computed. The weights are necessary for estimating the treatment effect in the matched sample; indeed, the weights determine the matched sample. While the weights for simple methods like 1:1 matching are straightforward (i.e., 1 if matched and 0 if unmatched), for more complicated scenarios, like full matching, matching with replacement, and variable ratio matching, the weights take on variable values and are critical to include in the analysis of the matched dataset. For example, full matching doesn’t discard any units (by default), but failing to include the matching weights in the estimation of the treatment effect would be like doing no matching at all.\nThere is very little guidance in the literature on how to compute matching weights. We have a few clues that have been scattered across different fields, but they have yet to describe a unifying method of computing these weights1. In this post, I’ll describe how matching weights are computed in MatchIt and how this unifying method relates to the few strategies described in the literature.\nThe main theses of this post are that matching is a nonparametric method for estimating propensity scores, and matching weights are propensity score weights. This framework unifies existing approaches for computing weights after matching, applies to all forms of matching (including \\(k\\):1 matching, full matching, and stratification), and is straightforward to implement.\nMatching as Nonparametric Estimation of Propensity Scores The first step in understanding how matching weights are computed is to consider how matching is a nonparametric estimator of the propensity score. When I talk about matching here, I’m really talking about the assignment of units into pairs, strata, or matched sets (Greifer and Stuart 2021). For example, 1:1 pair matching assigns treated and control units into pairs, each with one treated and one control unit. Optimal full matching assigns all units into matched sets, each with either exactly one treated unit and one or more control units or with exactly one control units and one or more treated units (Hansen and Klopfer 2006). Propensity score subclassification and coarsened exact matching assign units into strata based on their values of the propensity score or covariates, respectively (Rosenbaum and Rubin 1984; Iacus, King, and Porro 2012). I do want to note that matching with replacement is a slightly different beast, so I will save my discussion of it till later, though how it fits into this framework is straightforward.\nComputing stratum propensity scores For matched units, we can compute a new “stratum” propensity score, \\(\\hat{e}^*_i\\) as \\[ \\hat{e}^*_i = P(A = 1|S=s_i) \\]where \\(A\\) is the treatment (0 for control, 1 for treated) and \\(S\\) is stratum/pair membership indexed by strata \\(s\\). Put in words, the stratum propensity score \\(\\hat{e}^*_i\\) for each member of a matched stratum is the proportion of treated units in that stratum. We can also write this formula as \\[ \\hat{e}^*_i = \\frac{n_{1s_i}}{n_{s_i}} \\] where \\(n_{1s_i}\\) is the number of treated units in stratum \\(s_i\\) and \\(n_{s_i}\\) is the total number of units in stratum \\(s_i\\).\nNote that \\(\\hat{e}^*_i\\) is distinct from the usual propensity score, \\(\\hat{e}_i = P(A=1|X = x_i)\\), which is estimated from the treatment and covariates using, e.g., logistic regression or a machine learning model. \\(\\hat{e}_i\\) may be used to perform the matching or subclassification, but it is \\(\\hat{e}^*_i\\), the subject of this post, that arises from matching or subclassification. It is critical to keep these two propensity scores distinct; one is used to match (\\(\\hat{e}_i\\)), and the other results from matching (\\(\\hat{e}^*_i\\)).\nThis method of estimating stratum propensity scores is nonparametric in the sense that no model is used and no functional form assumption are made, once units have been assigned into strata. It may be that a model was used to assign units into strata (e.g., when matching or subclassifying based on a propensity score estimated with a model of treatment given the covariates), but, given the matching, this new propensity score is nonparametric. It is agnostic to how the matching was done.\nIntuitively, we can think of stratum membership as a proxy for the covariates that are usually included in a propensity score specification. That is, if all units in a stratum have the same values of the covariates, conditioning on stratum membership is the same as conditioning on the covariates.\n Examples In full matching, we may have some matched sets that have, for example, 1 treated unit and 7 control units. All units in that stratum would receive a stratum propensity score of \\(1/8\\). We might have another matched set that has 5 treated units and 1 control unit. All units in that stratum would receive a stratum propensity score of \\(5/6\\).\nIn 1:1 matching, the situation is more trivial; all matched units, which …","date":1685404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685404800,"objectID":"b8a60f781641f48a3be9f5147a2771c0","permalink":"https://ngreifer.github.io/blog/matching-weights/","publishdate":"2023-05-30T00:00:00Z","relpermalink":"/blog/matching-weights/","section":"blog","summary":"I’m often asked how the matching weights produced by MatchIt are computed. The weights are necessary for estimating the treatment effect in the matched sample; indeed, the weights determine the matched sample.","tags":["matching","propensity-scores"],"title":"Matching Weights are Propensity Score Weights","type":"blog"},{"authors":null,"categories":["R"],"content":" Multiply imputed data always makes things a little harder. Essentially, you have to perform each step of the analysis in each imputed dataset and then combine the results together in a special way. For basic regression analysis, the mice package makes fitting models and combining estimates simple. But when we want to do propensity score matching or weighting before fitting our regression models, and when the quantity we want to estimate is not just a coefficient in a regression model, things get a bit harder.\nFor doing matching or weighting in multiply imputed data, the R package {MatchThem} does the job. It essentially provides wrappers for MatchIt::matchit() and WeightIt::weightit() for multiply imputed data. It extends {mice}’s functionality for fitting regression models in multiply imputed data by automatically incorporating the matched or weighted structure into the estimation of the outcome models. It uses mice::pool() to pool estimates across multiply imputed data.\nBut for estimating treatment effects, it’s often not as simple as using a regression coefficient. If we include covariates in our outcome model but want a marginal effect, we need to use an average marginal effects procedure (i.e., g-computation) to compute it within each imputed dataset, and then combine the results afterward. The {marginaleffects} package provides a wonderful interface for performing g-computation, but for multiply imputed data, it can require some programming by the analyst. In this guide, I’ll show you how to do that programming to combine treatment effect estimates across multiple imputed datasets.\nAn alternative to using {marginaleffects} is to use the {clarify} package. {clarify} can also be used to perform g-computation, but it uses simulation-based inference to compute the uncertainty bounds for the estimate. An advantage of simulation-based inference for multiply imputed data is that combining estimates across imputed datasets is much more straightforward. In this guide, I’ll also show you how to use {clarify} to combine treatment effect estimates across imputed datasets.\nPackages we’ll need We will need the following packages for this demonstration: cobalt, mice, MatchThem, WeightIt, marginaleffects, and clarify.\n The data As usual, we’ll be using a version of the lalonde dataset. Here will use the lalonde_mis dataset in {cobalt}, which has missing values.\ndata(\u0026#34;lalonde_mis\u0026#34;, package = \u0026#34;cobalt\u0026#34;) summary(lalonde_mis) ## treat age educ race married nodegree re74 re75 re78 ## Min. :0.0000 Min. :16.00 Min. : 0.00 black :243 Min. :0.0000 Min. :0.0000 Min. : 0.0 Min. : 0.0 Min. : 0.0 ## 1st Qu.:0.0000 1st Qu.:20.00 1st Qu.: 9.00 hispan: 72 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.: 0.0 1st Qu.: 0.0 1st Qu.: 238.3 ## Median :0.0000 Median :25.00 Median :11.00 white :299 Median :0.0000 Median :1.0000 Median : 984.5 Median : 585.4 Median : 4759.0 ## Mean :0.3013 Mean :27.36 Mean :10.27 Mean :0.4158 Mean :0.6303 Mean : 4420.2 Mean : 2170.3 Mean : 6792.8 ## 3rd Qu.:1.0000 3rd Qu.:32.00 3rd Qu.:12.00 3rd Qu.:1.0000 3rd Qu.:1.0000 3rd Qu.: 7626.9 3rd Qu.: 3202.0 3rd Qu.:10893.6 ## Max. :1.0000 Max. :55.00 Max. :18.00 Max. :1.0000 Max. :1.0000 Max. :35040.1 Max. :25142.2 Max. :60307.9 ## NA\u0026#39;s :20 NA\u0026#39;s :40 NA\u0026#39;s :39 You can see there are some missing values in married, re74, and re75.\n Imputing the data Here, we’ll use {mice} to impute the data. Although typically something like 20 imputation is sufficient, for the method {clarify} uses, it needs way more, so we’ll use 50. We’ll use the default settings, but you should tailor the imputation to fit the needs of your dataset. (I always like to use a machine learning method for my imputations). We’ll also set a seed to ensure replicability.\nlibrary(\u0026#34;mice\u0026#34;) set.seed(12345) imp \u0026lt;- mice(lalonde_mis, m = 50, printFlag = FALSE) mice() returns a mids object, which contains the imputed datasets. Although we could extract the datasets using complete(), we’ll supply this object directly to our function for estimating the propensity score weights.\n Weighting the imputed data We’ll use MatchThem::weightthem() to estimate propensity score weights in the imputed datasets. We could also use MatchThem::matchthem() to do matching; the process is basically identical1. Here we’ll use logistic regression (🤢) to estimate ATT weights to keep things quick and simple.\nlibrary(\u0026#34;MatchThem\u0026#34;) w.imp \u0026lt;- weightthem(treat ~ age + educ + race + married + nodegree + re74 + re75, data = imp, method = \u0026#34;ps\u0026#34;, estimand = \u0026#34;ATT\u0026#34;) Let’s assess balance using {cobalt}.\nlibrary(\u0026#34;cobalt\u0026#34;) bal.tab(w.imp, stats = c(\u0026#34;m\u0026#34;, \u0026#34;ks\u0026#34;), abs = TRUE) ## Balance summary across all imputations ## Type Mean.Diff.Adj Max.Diff.Adj Mean.KS.Adj Max.KS.Adj ## prop.score Distance 0.0235 0.0379 0.1166 0.1327 ## age Contin. 0.1120 0.1343 0.3053 0.3146 ## educ Contin. 0.0352 0.0485 0.0369 0.0412 ## race_black Binary 0.0024 0.0036 0.0024 0.0036 ## race_hispan Binary 0.0003 0.0007 0.0003 0.0007 ## race_white Binary 0.0022 0.0030 0.0022 0.0030 ## married …","date":1675987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675987200,"objectID":"234eb4b23fdb18962d30bce146912cbd","permalink":"https://ngreifer.github.io/blog/treatment-effects-mi/","publishdate":"2023-02-10T00:00:00Z","relpermalink":"/blog/treatment-effects-mi/","section":"blog","summary":"Multiply imputed data always makes things a little harder. Essentially, you have to perform each step of the analysis in each imputed dataset and then combine the results together in a special way.","tags":["propensity-scores","R","multiple-imputation"],"title":"Estimating Treatment Effects After Weighting with Multiply Imputed Data","type":"blog"},{"authors":null,"categories":null,"content":" Genetic matching sounds cool and science-y, something we social scientists love because nobody thinks what we do is “real” science. And genetic matching is cool and science-y, but not because it has anything to do with genes or DNA. Genetic matching is a method of adjusting for confounding in observational studies; it is a close relative of propensity score matching and Mahalanobis distance matching and serves exactly the same purpose. Sekhon (2011) and Diamond and Sekhon (2013) describe genetic matching, but I’ll explain it here in simple terms and with an emphasis on its generality, which is undersold by its implementations.\nThis post won’t make any sense if you don’t know what matching in general is. Go read Stuart (2010), Greifer and Stuart (2021), and the MatchIt vignette on matching methods to learn about them. The focus here will be on pair matching, which involves assigning units to pairs or strata based on the distances between them, then discarding unpaired units.\nThe goal of matching is balanced samples, i.e., samples where the distribution of covariates in the treated and control groups is the same so that an estimated treatment effect cannot be said to be due to differences in the covariate distributions. Why, then, do we make pairs? Close pairs create balance, in theory. How do we compute how close units are to each other? There are several ways; a common one is the Mahalanobis distance, as described for matching in Rubin (1980), and which I’ll describe here.\nThe Mahalanobis distance between two units \\(i\\) and \\(j\\) is defined as\n\\[ \\delta^{md}_{i,j}=\\sqrt{(\\mathbf{x}_i-\\mathbf{x}_j)\\Sigma^{-1}(\\mathbf{x}_i-\\mathbf{x}_j)\u0026#39;} \\]\nwhere \\(\\mathbf{x}_i\\) is the vector of covariates for unit \\(i\\) (i.e., that unit’s row in the dataset) and \\(\\Sigma\\) is the covariance matrix of the covariates1. Equivalently, the Mahalanobis distance is the Euclidean distance (i.e., the regular distance) computed on the standardized principal components. The Mahalanobis distance is an improvement over the Euclidean distance of the covariates because it standardizes the covariates to be on the same scale and adjusts for correlations between covariates (so two highly correlated variables only count once). A great description of the Mahalanobis distance is here (though there it is not described in the context of matching).\nGenetic matching concerns a generalization of the Mahalanobis distance, called the generalized Mahalanobis distance, which additionally involves a weight matrix. The generalized Mahalanobis distance is defined as\n\\[ \\delta^{gmd}_{i,j}(W)=\\sqrt{(\\mathbf{x}_i-\\mathbf{x}_j)\u0026#39;\\left(\\Sigma^{-\\frac{1}{2}}\\right)\u0026#39; W\\Sigma^{-\\frac{1}{2}}(\\mathbf{x}_i-\\mathbf{x}_j)} \\]\nwhere \\(\\Sigma^{-\\frac{1}{2}}\\) is the “square root” of the inverse of the covariance matrix (e.g., the Cholesky decomposition), and \\(W\\) is a symmetric weight matrix that can contain anything but in most cases is a diagonal matrix with a scalar weight for each covariate in \\(\\mathbf{x}\\) (not weights for each unit like in propensity score weighting; a weight for each covariate), i.e., \\(W = \\text{diag}(\\begin{bmatrix} w_1 \u0026amp; \\dots \u0026amp; w_p \\end{bmatrix})\\). The generalized Mahalanobis distance is equal to the usual Mahalanobis distance when \\(W=I\\), the identity matrix.\nWhat does any of this have to do with genetic matching? Well, “genetic matching” is a bit of a misnomer; it’s not a matching method. It’s a method of estimating \\(W\\). Genetic matching finds the \\(W\\) that, when incorporated in a generalized Mahalanobis distance used to match treated and control units, yields the best balance. Once you have found \\(W\\), you then do a regular round of matching, and that is your matched sample.\nTo put it slightly more formally, consider a function \\(\\text{match}(\\delta)\\), which takes in a distance matrix \\(\\delta\\) and produces a matched set of treated and control units, characterized by a set of matching weights (e.g., 1 if matched, 0 if unmatched) and pair membership for each unit. Consider a function \\(\\text{imbalance}(m)\\), which takes in the output of a \\(\\text{match}(\\delta)\\) and returns a scalar imbalance metric (e.g., the largest absolute standardized mean difference among all the covariates). We can then write the genetic matching problem as the following:\n\\[ \\underset{W}{\\operatorname{arg\\,min}} \\, \\text{imbalance}(\\text{match}(\\delta^{gmd}(W))) \\]\nGenetic matching is very general; there are many ways to do the matching (i.e., many ways to specify the \\(\\text{match}()\\) function) and many ways to characterize imbalance (i.e., many ways to specify the \\(\\text{imbalance}()\\) function) (and even several ways to specific \\(\\delta()\\)!). Although nearest neighbor matching is often used for \\(\\text{match}()\\), any matching method that uses a distance matrix could be as well. A specific imbalance measure (which I’ll explain in more detail later) is most often used for \\(\\text{imbalance}()\\) because it is the default in the software that …","date":1665187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665187200,"objectID":"1b788514d90afeaa9df4e6c04f68115a","permalink":"https://ngreifer.github.io/blog/genetic-matching/","publishdate":"2022-10-08T00:00:00Z","relpermalink":"/blog/genetic-matching/","section":"blog","summary":"Genetic matching sounds cool and science-y, something we social scientists love because nobody thinks what we do is “real” science. And genetic matching is cool and science-y, but not because it has anything to do with genes or DNA.","tags":["matching","R"],"title":"Genetic Matching, from the Ground Up","type":"blog"},{"authors":null,"categories":null,"content":" Today I’m going to demonstrate performing a subgroup analysis after propensity score matching using R. Subgroup analysis, also known as moderation analysis or the analysis of effect modification, concerns the estimation of treatment effects within subgroups of a pre-treatment covariate. This post assumes you understand how to do propensity score matching. For a general introduction to propensity score matching, I recommend Austin (2011) and the {MatchIt} introductory vignette. If you understand inverse probability weighting but aren’t too familiar with matching, I recommend my article with Liz Stuart (Greifer and Stuart 2021). For an introduction to subgroup analysis with propensity scores, you can also check out Green and Stuart (2014). Here, I’ll mainly try to get to the point.\nThe dataset we’ll use today is the famous Lalonde dataset, investigating the effect of a job training program on earnings. We’ll use the version of this dataset that comes with the {MatchIt} package.\ndata(\u0026#34;lalonde\u0026#34;, package = \u0026#34;MatchIt\u0026#34;) head(lalonde) ## treat age educ race married nodegree re74 re75 re78 ## NSW1 1 37 11 black 1 1 0 0 9930.0460 ## NSW2 1 22 9 hispan 0 1 0 0 3595.8940 ## NSW3 1 30 12 black 0 0 0 0 24909.4500 ## NSW4 1 27 11 black 0 1 0 0 7506.1460 ## NSW5 1 33 8 black 0 1 0 0 289.7899 ## NSW6 1 22 9 black 0 1 0 0 4056.4940 The treatment is treat, the outcome in the original study was re78 (1978 earnings), and the other variables are pretreatment covariates that we want to adjust for using propensity score matching. In this example, I’ll actually be using a different outcome, re78_0, which is whether the participant’s 1978 earnings were equal to 0 or not, because I want to demonstrate the procedure for a binary outcome. So, we hope the treatment effect is negative, i.e., the risk of 0 earnings decreases for those in the treatment.\nlalonde$re78_0 \u0026lt;- as.numeric(lalonde$re78 == 0) Our moderator will be race, a 3-category factor variable.\nwith(lalonde, table(race)) ## race ## black hispan white ## 243 72 299 Our estimand will be the subgroup-specific and marginal average treatment effect on the treated (ATT), using the risk difference as our effect measure.\nPackages You’ll Need We’ll need a few R packages for this analysis. We’ll need {MatchIt} and {optmatch} for the matching, {cobalt} for the balance assessment, {marginaleffects} for estimating the treatment effects, and {sandwich} for computing the standard errors. You can install those using the code below:\ninstall.packages(c(\u0026#34;MatchIt\u0026#34;, \u0026#34;optmatch\u0026#34;, \u0026#34;cobalt\u0026#34;, \u0026#34;marginaleffects\u0026#34;, \u0026#34;sandwich\u0026#34;)) Let’s get into it!\n Step 1: Subgroup Matching Our first step is to perform the matching. Although there are a few strategies for performing matching for subgroup analysis, in general subgroup-specific matching tends to work best, though it requires a little extra work.\nWe’ll do this by splitting the dataset by race and performing a separate matching analysis within each one.\n#Splitting the data lalonde_b \u0026lt;- subset(lalonde, race == \u0026#34;black\u0026#34;) lalonde_h \u0026lt;- subset(lalonde, race == \u0026#34;hispan\u0026#34;) lalonde_w \u0026lt;- subset(lalonde, race == \u0026#34;white\u0026#34;) Here we’ll use full matching because 1:1 matching without replacement, the most common (but worst) way to do propensity score matching, doesn’t work well in this dataset. The process described below works exactly the same for 1:1 and most other kinds of matching as it does for full matching. We’ll estimate propensity scores in each subgroup, here using probit regression, which happens to yield better balance than logistic regression does.\nlibrary(\u0026#34;MatchIt\u0026#34;) #Matching in race == \u0026#34;black\u0026#34; m.out_b \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_b, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;) #Matching in race == \u0026#34;hispan\u0026#34; m.out_h \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_h, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;) #Matching in race == \u0026#34;black\u0026#34; m.out_w \u0026lt;- matchit(treat ~ age + educ + married + nodegree + re74 + re75, data = lalonde_w, method = \u0026#34;full\u0026#34;, estimand = \u0026#34;ATT\u0026#34;, link = \u0026#34;probit\u0026#34;)  Step 2: Assessing Balance within Subgroups We need to assess subgroup balance; we can do that using summary() on each matchit object, or we can use functions from {cobalt}.\nBelow are examples of using summary() and cobalt::bal.tab() on one matchit object at a time1:\nsummary(m.out_b) ## ## Call: ## matchit(formula = treat ~ age + educ + married + nodegree + re74 + ## re75, data = lalonde_b, method = \u0026#34;full\u0026#34;, link = \u0026#34;probit\u0026#34;, ## estimand = \u0026#34;ATT\u0026#34;) ## ## Summary of Balance for All Data: ## Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max ## distance 0.6587 0.6121 0.4851 0.7278 0.1134 0.1972 ## age 25.9808 26.0690 -0.0121 0.4511 0.0902 0.2378 ## educ 10.3141 10.0920 0.1079 0.5436 0.0336 0.0807 ## married 0.1859 0.2874 -0.2608 . 0.1015 0.1015 ## nodegree 0.7244 0.6437 0.1806 . 0.0807 0.0807 ## re74 2155.0132 3117.0584 -0.1881 0.9436 0.0890 0.2863 ## re75 1490.7221 1834.4220 …","date":1662336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662336000,"objectID":"2ce2bc3725b3a8aff6cde5b4b0c90240","permalink":"https://ngreifer.github.io/blog/subgroup-analysis-psm/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/blog/subgroup-analysis-psm/","section":"blog","summary":"Today I’m going to demonstrate performing a subgroup analysis after propensity score matching using R. Subgroup analysis, also known as moderation analysis or the analysis of effect modification, concerns the estimation of treatment effects within subgroups of a pre-treatment covariate.","tags":["matching","propensity-scores","R","subgroup analysis"],"title":"Subgroup Analysis After Propensity Score Matching Using R","type":"blog"},{"authors":null,"categories":null,"content":"This page documents the software packages I have worked on. If you have any questions about them, please submit your question to their GitHub issues page rather than emailing me. You are also welcome to ask a question on StackOverflow or CrossValidated, which I check often.\nR packages These packages are ones that I am a primary author on and have expertise on the methods implemented. I consider these packages to be “mine”, at least partly, in the sense that I can speak not only on the implementation but on the methods as well.\n cobalt: Covariate Balance Tables and Plots  Noah Greifer | website | CRAN | source   WeightIt: Weighting for Covariate Balance in Observational Studies  Noah Greifer | website | CRAN | source   MatchIt: Nonparametric Preprocessing for Parametric Causal Inference  Daniel Ho, Kosuke Imai, Gary King, Elizabeth Stuart, and Noah Greifer | website | CRAN | source   MatchThem: Matching and Weighting Multiply Imputed Datasets  Farhad Pishgar and Noah Greifer | CRAN | source   optweight: Targeted Stable Balancing Weights Using Optimization  Noah Greifer | CRAN | source   MatchingFrontier: Computation of the Balance-Sample Size Frontier in Matching Methods for Causal Inference  Gary King, Christopher Lucas, Richard Nielsen, and Noah Greifer | website | source   fwb: Fractional Weighted Bootstrap  Noah Greifer | website | CRAN | source   clarify: Simulation-Based Inference for Regression Models  Noah Greifer, Steven Worthington, Stefano Iacus, and Gary King | website | CRAN | source    These packages are ones that I have developed as part of my job but which I don’t consider “mine” in the sense that I am not the primary maintainer and I don’t have expertise on the methods implemented. Please do not contact me about these packages.\n  netlit: Augment a literature review with network analysis statistics\n Devin Judge-Lord and Noah Greifer | website | source    EvoPhylo: Pre- And Postprocessing of Morphological Data from Relaxed Clock Bayesian Phylogenetics\n Tiago Simões, Noah Greifer, and Stephanie Pierce | website | CRAN | source    Morphoscape: Computation and Visualization of Adaptive Landscapes\n Blake Dickson, Stephanie Pierce, and Noah Greifer | website | CRAN | source    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6fcae98d7df3b6c44952e7b5fed181e3","permalink":"https://ngreifer.github.io/software/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/software/","section":"","summary":"This page documents the software packages I have worked on. If you have any questions about them, please submit your question to their GitHub issues page rather than emailing me. You are also welcome to ask a question on StackOverflow or CrossValidated, which I check often.","tags":null,"title":"Software","type":"page"}]